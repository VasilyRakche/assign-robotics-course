{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f00839c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**ry-c++-log** ry.cpp:init_LogToPythonConsole:34(0) initializing ry log callback\n",
      "\n",
      "**ry-c++-log** util.cpp:initCmdLine:545(1) ** cmd line arguments: 'rai-pybind -python '** INFO:ry.cpp:init_LogToPythonConsole:34(0) initializing ry log callback\n",
      "\n",
      "\n",
      "**ry-c++-log** util.cpp:initCmdLine:549(1) ** run path: '/home/vasko/Documents/TUB3/AI_Robotics/robotics-course/course3-Simulation'** INFO:util.cpp:initCmdLine:545(1) ** cmd line arguments: 'rai-pybind -python '\n",
      "\n",
      "\n",
      "** INFO:util.cpp:initCmdLine:549(1) ** run path: '/home/vasko/Documents/TUB3/AI_Robotics/robotics-course/course3-Simulation'\n",
      "**ry-c++-log** graph.cpp:initParameters:1379(1) ** parsed parameters:\n",
      "{python}\n",
      "\n",
      "\n",
      "** INFO:graph.cpp:initParameters:1379(1) ** parsed parameters:\n",
      "{python}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../build')\n",
    "import numpy as np\n",
    "import libry as ry\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d5d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RealWorld = ry.Config()\n",
    "# RealWorld.addFile('../scenarios/pandasTable.g')\n",
    "\n",
    "# box = RealWorld.addFrame(\"box\")\n",
    "# box.setShape(ry.ST.ssBox, [0.2, 0.2, 0.2, 0.02])\n",
    "# box.setColor([1,0,0])\n",
    "# box.setPosition([0.5, 0.1, 0.75])\n",
    "# box.setQuaternion([0.86,0,0,0.5])\n",
    "# box.setContact(1)\n",
    "# box.setMass(0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cab5b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ball = RealWorld.addFrame(\"ball\")\n",
    "# ball.setShape(ry.ST.sphere, [0.05])\n",
    "# ball.setPosition([0.1, 0.1, 0.7])\n",
    "# ball.setColor([1,0,0])\n",
    "# ball.setContact(1)\n",
    "# ball.setMass(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae37d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S = RealWorld.simulation(ry.SimulatorEngine.bullet, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af8d42a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = ry.Config()\n",
    "# ball.setPosition([2, 0.1, 0.7])\n",
    "# D = C.view();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b55f3563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box.setPosition([0.8, 0.1, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "632167e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ball.setPosition([2, 0.1, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e534d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S.step(np.zeros(q.shape), .01, ry.ControlMode.velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d468efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = S.get_q()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "972f7cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3be998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for t in range(100):    \n",
    "# #         gt_pos = ball.getPosition()\n",
    "\n",
    "    \n",
    "#     S.step(np.zeros(q.shape), tau, ry.ControlMode.velocity)\n",
    "#     time.sleep(tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d164a148",
   "metadata": {},
   "source": [
    "### Euler Angles From quaternions\n",
    "https://stackoverflow.com/questions/57063595/how-to-obtain-the-angle-between-two-quaternions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ddd4695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyquaternion import Quaternion\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b8b5f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi_to_quat(psi):\n",
    "    return [math.cos(psi/2),0,0,math.sin(psi/2)]\n",
    "\n",
    "def quat_to_psi(qd):\n",
    "    return math.atan2( 2 * (qd.w * qd.z + qd.x * qd.y), 1 - 2 * (qd.y**2 + qd.z**2) )\n",
    "    \n",
    "def get_z_angle_diff(frame1, frame2):\n",
    "    q1 = Quaternion(frame1.getQuaternion())\n",
    "    q = Quaternion(frame2.getQuaternion())\n",
    "\n",
    "    qd = q.conjugate * q1\n",
    "\n",
    "    # Calculate Euler angles from this difference quaternion\n",
    "    # phi   = math.atan2( 2 * (qd.w * qd.x + qd.y * qd.z), 1 - 2 * (qd.x**2 + qd.y**2) )\n",
    "    # theta = math.asin ( 2 * (qd.w * qd.y - qd.z * qd.x) )\n",
    "    psi   = quat_to_psi(qd)\n",
    "    \n",
    "    return psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60435c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_position_diff(frame1,frame2):\n",
    "    res = frame1.getPosition() - frame2.getPosition()\n",
    "    return res[0], res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c2ff459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rad_to_deg(angle):\n",
    "    return angle/(2*math.pi)*360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae52ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_direction(frame, code):\n",
    "    qd = Quaternion(frame.getQuaternion())\n",
    "    psi   = math.atan2( 2 * (qd.w * qd.z + qd.x * qd.y), 1 - 2 * (qd.y**2 + qd.z**2) )\n",
    "    \n",
    "    R = np.array([[math.cos(psi), -math.sin(psi)],\n",
    "                     [math.sin(psi), math.cos(psi)]])\n",
    "    vel = 1\n",
    "    dist = .22 \n",
    "    offset = .1\n",
    "    \n",
    "    if code == 0:\n",
    "        rel_start = np.array([-offset, -dist])\n",
    "        direction = np.array([0, vel])\n",
    "    elif code == 1:\n",
    "        rel_start = np.array([0, -dist])\n",
    "        direction = np.array([0, vel])\n",
    "    elif code == 2:  \n",
    "        rel_start = np.array([offset, -dist])\n",
    "        direction = np.array([0, vel])\n",
    "    elif code == 3:     \n",
    "        rel_start = np.array([dist, -offset])\n",
    "        direction = np.array([-vel, 0])\n",
    "    elif code == 4:     \n",
    "        rel_start = np.array([dist, 0])\n",
    "        direction = np.array([-vel, 0])\n",
    "    elif code == 5:     \n",
    "        rel_start = np.array([dist, offset])\n",
    "        direction = np.array([-vel, 0])\n",
    "    elif code == 6:     \n",
    "        rel_start = np.array([offset, dist])\n",
    "        direction = np.array([0, -vel])\n",
    "    elif code == 7:     \n",
    "        rel_start = np.array([0, dist])\n",
    "        direction = np.array([0, -vel])\n",
    "    elif code == 8:     \n",
    "        rel_start = np.array([-offset, dist])\n",
    "        direction = np.array([0, -vel])\n",
    "    elif code == 9:     \n",
    "        rel_start = np.array([-dist, offset])\n",
    "        direction = np.array([vel, 0])\n",
    "    elif code == 10:   \n",
    "        rel_start = np.array([-dist, 0])\n",
    "        direction = np.array([vel, 0])\n",
    "    elif code == 11: \n",
    "        rel_start = np.array([-dist, -offset])\n",
    "        direction = np.array([vel, 0])\n",
    "    \n",
    "    pos = frame.getPosition()[:2] + R.dot(rel_start)\n",
    "    direction = R.dot(direction)\n",
    "    return list(pos) + [frame.getPosition()[2]] ,  list(direction) + [0.]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f214707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9688670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = ry.Config()\n",
    "# C.addFile(\"../scenarios/pushSimWorld.g\")\n",
    "# box_t = C.getFrame(\"box_t\")\n",
    "# box = C.getFrame(\"box\")\n",
    "# # box_t.setPosition(box.getPosition())\n",
    "# ball = C.getFrame(\"ball\")\n",
    "# S = C.simulation(ry.SimulatorEngine.bullet, True)\n",
    "\n",
    "# # Get angle and position diff\n",
    "# za_diff = get_z_angle_diff(box_t, box)\n",
    "# x_diff, y_diff = get_xy_position_diff(box_t, box)\n",
    "\n",
    "#save the state and revert later \n",
    "\n",
    "\n",
    "# tau = 0.01\n",
    "# for t in range(1000):\n",
    "#     time.sleep(tau)\n",
    "#     if t%10 == 0 :\n",
    "#         start, direction = start_direction(box,t%11)\n",
    "#         ball.setPosition(start)\n",
    "#     S.step(direction, 0.01,  ry.ControlMode.velocity)\n",
    "    \n",
    "#Reset the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0803724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_move = [0]*12\n",
    "# final_move[11] = 1.\n",
    "# game_step(final_move, box, box_t, ball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b430d170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3\n"
     ]
    }
   ],
   "source": [
    "world_configuration = \"../scenarios/pushSimWorld.g\"\n",
    "C = ry.Config()\n",
    "C.addFile(world_configuration)\n",
    "\n",
    "\n",
    "box = C.getFrame(\"box\")\n",
    "box_start_state = box.getPosition()\n",
    "box_t = C.getFrame(\"box_t\")\n",
    "ball = C.getFrame(\"ball\")\n",
    "x_start, y_start = get_xy_position_diff(box_t, box)\n",
    "r_start = (x_start**2 + y_start**2)**.5 \n",
    "print(r_start)\n",
    "game_over_threshold = 1.\n",
    "reward_threshold = .1\n",
    "score = 0\n",
    "state = 3*[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34e92f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box_marker = C.addFrame(\"box_marker\", parent=\"box\" )\n",
    "# box_marker.setShape(ry.ST.ssBox, [0.01, 0.15, 0.1, 0.01])\n",
    "# box_marker.setColor([1,0,0,0.5])\n",
    "# box_marker.setPosition(box.getPosition()+[0.0, -0.07, 0.02])\n",
    "\n",
    "# box_t_marker = C.addFrame(\"box_marker\", parent=\"box_t\" )\n",
    "# box_t_marker.setShape(ry.ST.ssBox, [0.01, 0.15, 0.1, 0.01])\n",
    "# box_t_marker.setColor([1,.5,0,0.5])\n",
    "# box_t_marker.setPosition(box_t.getPosition()+[0.0, -0.07, 0.02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88ee2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = C.simulation(ry.SimulatorEngine.bullet, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1516cf0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2831852468518707"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box.setQuaternion(psi_to_quat(5))\n",
    "S.setState(C.getFrameState())\n",
    "S.step([], 0,  ry.ControlMode.none)\n",
    "get_z_angle_diff(box_t, box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e910917",
   "metadata": {},
   "outputs": [],
   "source": [
    " for t in range(6):\n",
    "            time.sleep(self.tau)\n",
    "            self.S.step(direction, self.tau,  ry.ControlMode.velocity)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4c8c418",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3615313337.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [56]\u001b[0;36m\u001b[0m\n\u001b[0;31m    def step(self, final_move):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class Game:\n",
    "\n",
    "    def __init__(self, world_configuration = \"../scenarios/pushSimWorld.g\"):\n",
    "        self.C = ry.Config()\n",
    "        self.C.addFile(world_configuration)\n",
    "        self.S = self.C.simulation(ry.SimulatorEngine.bullet, True)\n",
    "        \n",
    "        self.tau = 0.0001\n",
    "        self.box = self.C.getFrame(\"box\")\n",
    "        self.box_t = self.C.getFrame(\"box_t\")\n",
    "        self.ball = self.C.getFrame(\"ball\")\n",
    "        self.r_max = 2.\n",
    "        self.disc_r = .3\n",
    "        self.disc_angle = .5 # TODO: define meaningful angle\n",
    "        self.state = 3*[0]\n",
    "        self.start_r = 0\n",
    "        self.start_angle = 0\n",
    "        self.score = 0\n",
    "        \n",
    "        # random initialization \n",
    "        self.reset()\n",
    "        \n",
    "    def calculate_state(self):\n",
    "        x_diff, y_diff = get_xy_position_diff(self.box_t, self.box)\n",
    "        z_angle_diff = get_z_angle_diff(self.box_t, self.box)\n",
    "        \n",
    "        self.state = [x_diff, y_diff, z_angle_diff]\n",
    "\n",
    "        \n",
    "    def step(self, final_move):\n",
    "        reward = 0\n",
    "        game_over = False\n",
    "\n",
    "        start, direction = start_direction(self.box,np.nonzero(final_move)[0][0])\n",
    "        self.ball.setPosition(start)\n",
    "        self.S.setState(self.C.getFrameState())\n",
    "        \n",
    "        # Updating the environment\n",
    "        self.S.step([], 0,  ry.ControlMode.none)\n",
    "\n",
    "        for t in range(6):\n",
    "            time.sleep(self.tau)\n",
    "            self.S.step(direction, self.tau,  ry.ControlMode.velocity)\n",
    "        \n",
    "        \n",
    "        self.calculate_state();\n",
    "        \n",
    "        r = (self.state[0]**2 + self.state[1]**2)**.5\n",
    "        \n",
    "        dr = int(r / self.disc_r)\n",
    "        dangle = int(self.state[2] / self.disc_angle)\n",
    "        \n",
    "        \n",
    "        if r >= self.r_max: \n",
    "            reward = -3.\n",
    "            game_over = True        \n",
    "            \n",
    "        elif dr < self.prev_dr:\n",
    "            #TODO: dangle adding strategy\n",
    "            reward = (self.prev_dr - dr)\n",
    "            self.prev_dr = dr\n",
    "            \n",
    "        elif r < 0.01:\n",
    "            game_over = True\n",
    "            reward = 10 - abs(dangle)\n",
    "            \n",
    "         \n",
    "        # penalize angle difference increase \n",
    "        if abs(self.prev_dangle)<abs(dangle):\n",
    "            reward -= -1\n",
    "            self.prev_dangle = dangle\n",
    "            \n",
    "        self.score += reward\n",
    "        return reward, game_over, self.score\n",
    "        \n",
    "    def get_state(self):\n",
    "        return self.state\n",
    "    \n",
    "    def reset(self):\n",
    "        #define the new state of the box to be somewhere around the target:\n",
    "        new_state = np.array(self.box_t.getPosition())+np.array([1.5*np.random.rand(),1.5*np.random.rand(),0])\n",
    "        \n",
    "        self.box.setQuaternion(psi_to_quat(2*math.pi*np.random.rand()))\n",
    "        self.box.setPosition(new_state)\n",
    "        self.S.setState(self.C.getFrameState())\n",
    "        \n",
    "        self.calculate_state();\n",
    "        \n",
    "        r = (self.state[0]**2 + self.state[1]**2)**.5\n",
    "        \n",
    "        self.prev_dr = int(r / self.disc_r)\n",
    "        self.prev_dangle = int(self.state[2] / self.disc_angle)\n",
    "        \n",
    "        self.score = 0\n",
    "        \n",
    "        # Updating the environment\n",
    "        self.S.step([], 0,  ry.ControlMode.none)\n",
    "        \n",
    "#         for t in range(2):\n",
    "#             time.sleep(self.tau)\n",
    "#             self.S.step([], self.tau,  ry.ControlMode.none)            \n",
    "\n",
    "        return \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "911924cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6631741457575441"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a191582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box.setQuaternion([.966, 0., 0., 0.259])\n",
    "# qd = Quaternion(box.getQuaternion())\n",
    "# psi   = math.atan2( 2 * (qd.w * qd.z + qd.x * qd.y), 1 - 2 * (qd.y**2 + qd.z**2) )\n",
    "# psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfc42861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.agent import Agent\n",
    "from lib.helper import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ace5fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSchedule(object):\n",
    "    def __init__(self, schedule_timesteps, final_p, initial_p):\n",
    "        self.schedule_timesteps = schedule_timesteps\n",
    "        self.final_p = final_p\n",
    "        self.initial_p = initial_p\n",
    "\n",
    "    def value(self, t):\n",
    "        fraction = min(1.0, float(t) / self.schedule_timesteps)\n",
    "        return self.initial_p + (self.final_p - self.initial_p) * fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "from collections import deque\n",
    "import lib.logger\n",
    "import torch\n",
    "\n",
    "class Worker:\n",
    "    def __init__(self, \n",
    "                    # epsilon params\n",
    "                    fraction_eps = 0.1, \n",
    "                    initial_eps = 0.05, \n",
    "                    final_eps = 0.1, \n",
    "\n",
    "                    # learning \n",
    "                    max_steps = 10_000_000, \n",
    "                    gamma = 0.97, \n",
    "                    learning_rate = 1e-3, \n",
    "                    learning_start_itr = 0, \n",
    "                    train_q_freq = 50,\n",
    "\n",
    "                    # memory \n",
    "                    memory_len = 100_000,\n",
    "                    batch_size = 1000,\n",
    "\n",
    "                    #network\n",
    "                    layers_sizes = [3, 256, 12],\n",
    "\n",
    "                    #logging\n",
    "                    log_freq = 1000,\n",
    "                    log_dir = \"data/local/game\",\n",
    "                ):\n",
    "\n",
    "        lib.logger.session(log_dir).__enter__()\n",
    "        self.log_freq = log_freq\n",
    "        self.train_q_freq = train_q_freq\n",
    "        self.layers_sizes = layers_sizes\n",
    "        self.act_dim = self.layers_sizes[-1]\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "        # Learning Agent \n",
    "        self.agent = Agent(\n",
    "            gamma = gamma, \n",
    "            learning_rate = learning_rate, \n",
    "            memory_len = memory_len, \n",
    "            layers_sizes = self.layers_sizes,\n",
    "            batch_size = batch_size\n",
    "            )\n",
    "\n",
    "        # Environment\n",
    "        self.game = Game()\n",
    "\n",
    "        # Tactics for exploraion/exploitation\n",
    "        self.exploration = LinearSchedule(\n",
    "            schedule_timesteps=int(fraction_eps * max_steps),\n",
    "            initial_p=initial_eps,\n",
    "            final_p=final_eps)\n",
    "\n",
    "\n",
    "    def eps_greedy(self, state, epsilon):\n",
    "        act = [0]*self.act_dim\n",
    "\n",
    "        # Check Q function, do argmax.\n",
    "        rnd = np.random.rand()\n",
    "        if rnd > epsilon:\n",
    "            state0 = torch.tensor(state, dtype=torch.float)\n",
    "            prediction = self.agent.model(state0)\n",
    "            move = torch.argmax(prediction).item()\n",
    "            act[move] = 1\n",
    "        else:\n",
    "            act[np.random.randint(0, self.act_dim)] = 1\n",
    "        \n",
    "        return act\n",
    "\n",
    "    def train(self):\n",
    "        plot_scores = []\n",
    "        plot_mean_scores = []\n",
    "        episode_rewards = []\n",
    "        total_score = 0\n",
    "        record = 0     \n",
    "        log_itr = 0\n",
    "\n",
    "        l_episode_return = deque([], maxlen=10)\n",
    "        l_tq_squared_error = deque(maxlen=50)   \n",
    "        \n",
    "        for itr in range(self.max_steps):\n",
    "            # get old state\n",
    "            state_old = self.game.get_state()\n",
    "\n",
    "            # get move\n",
    "            act = self.eps_greedy(state_old, self.exploration.value(itr))\n",
    "\n",
    "            # perform move and get new state\n",
    "            reward, done, score = self.game.step(act)\n",
    "            state_new = self.game.get_state()\n",
    "\n",
    "            episode_rewards.append(reward)\n",
    "\n",
    "            # train short memory\n",
    "            self.agent.train_short_memory(state_old, act, reward, state_new, done)\n",
    "\n",
    "            # remember\n",
    "            self.agent.remember(state_old, act, reward, state_new, done)\n",
    "\n",
    "            if done:\n",
    "                # train long memory, plot result\n",
    "    #             print(\"done routine\")\n",
    "                self.game.reset()\n",
    "                episode_return = np.sum(episode_rewards)\n",
    "\n",
    "                if score > record:\n",
    "                    record = score\n",
    "                    self.agent.model.save()\n",
    "\n",
    "                l_episode_return.append(episode_return)\n",
    "\n",
    "                td_squared_error = self.agent.train_long_memory().data\n",
    "\n",
    "                l_tq_squared_error.append(td_squared_error)\n",
    "\n",
    "                # print('Game', itr, 'Score', score, 'Record:', record)\n",
    "\n",
    "                # plot_scores.append(score)\n",
    "                # total_score += score\n",
    "                # mean_score = total_score / itr\n",
    "                # plot_mean_scores.append(mean_score)\n",
    "                # plot(plot_scores, plot_mean_scores)\n",
    "\n",
    "            # if itr % self.train_q_freq == 0 and itr > self.learning_start_itr:\n",
    "            #     td_squared_error = self.agent.train_long_memory()\n",
    "            #     l_tq_squared_error.append(td_squared_error)\n",
    "\n",
    "            if (itr + 1) % self.log_freq == 0 and len(l_episode_return) > 5:\n",
    "                log_itr += 1\n",
    "                lib.logger.logkv('Iteration', log_itr)\n",
    "                lib.logger.logkv('Steps', itr)\n",
    "                lib.logger.logkv('Epsilon', self.exploration.value(itr))\n",
    "                lib.logger.logkv('Episodes', len(l_episode_return))\n",
    "                lib.logger.logkv('AverageReturn', np.mean(l_episode_return))\n",
    "                lib.logger.logkv('TDError^2', np.mean(l_tq_squared_error))\n",
    "                lib.logger.dumpkvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a79d709",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'torch.dtype' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m setup \u001b[38;5;241m=\u001b[39m Worker()\n\u001b[0;32m----> 2\u001b[0m \u001b[43msetup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36mWorker.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m lib\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlogkv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpisodes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(l_episode_return))\n\u001b[1;32m    138\u001b[0m lib\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlogkv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverageReturn\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(l_episode_return))\n\u001b[0;32m--> 139\u001b[0m lib\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlogkv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTDError^2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml_tq_squared_error\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    140\u001b[0m lib\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdumpkvs()\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3369\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3370\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3373\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/_methods.py:170\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    168\u001b[0m         ret \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(ret \u001b[38;5;241m/\u001b[39m rcount)\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[43mret\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m(ret \u001b[38;5;241m/\u001b[39m rcount)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     ret \u001b[38;5;241m=\u001b[39m ret \u001b[38;5;241m/\u001b[39m rcount\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'torch.dtype' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "setup = Worker()\n",
    "setup.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bceafc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
